# Capstone

The ![Final Report](https://www.github.com/alewan/capstone/blob/develop/FinalReport.pdf) contains a detailed description of this project.

The executive summary is available below for convenience:

Autism Spectrum Disorder (ASD) is a severe developmental disability, which involves “impairments in social interaction… and verbal and nonverbal communication” [1]. Our team has seen first hand the challenges that these children experience in communicating. With this understanding, the team decided on the goal of building an application that will act as a learning tool for children with autism who have difficulty interpreting verbal and nonverbal social cues. This application is a web application designed to analyze video and audio data and produce results in an easy-to-understand interface, allowing children to practice and better comprehend the world around them.


After outlining the project goal, key functional requirements, objectives, and constraints (FOCs), we established an appropriate scope for the project and refined what would be expected from the final solution. This includes expectations on what will be classified and requirements for compliance with applicable laws and regulations. These FOCs also include validation/acceptance tests which define precisely how they would be verified.


Over the course of several months, the team designed and executed the components of the system, and created an application that is able to execute its intended function. The final design consists of five primary components, which were built modularly and integrated into a single pipeline. The components consist of a user interface, data pre-processing,  audio neural network, image-based classification, and a gradient boosting decision tree. The technical challenges of this project led to important design decisions, including type of data input and machine learning methods used. The final product is a functional application that is targeted towards children with autism as a learning tool. The application is able to accept video files as input and provide an emotion prediction with an accuracy of approximately 71%.  


The validation tests that the team set out to achieve show the success of the final application. These tests range from quantitative numerical results to interactive, useability features, and test all components of our system. Overall, the team has observed that the functionality and purpose of the project was achieved. We recognize that some of the technical challenges in the nature of this project and specifically with audio data analysis and classification led to final accuracies slightly below our intended numbers. However, we see this as a learning process, and opportunity for future steps to be taken. The team sees an exciting potential future for this application, with essential next steps to improve technical and useability components of the application. We believe that there is a need for these kinds of educational tools in society, and that our application could fill this gap.